{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on using sklearn for breast cancer\n",
    "- implement a simple machine learning algorithm in Python using Scikit-learn\n",
    "- Using a database of breast cancer tumor information, use a Naive Bayes (NB) classifer that predicts whether or not a tumor is malignant or benign.\n",
    "\n",
    "Source for tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the breast cancer dataset\n",
    "- includes various information about breast cancer tumors, as well as classification labels of malignant or benign\n",
    "-  dataset has 569 *instances*, or data, on 569 tumors and includes information on 30 *attributes*, or features, such as the radius of the tumor, texture, smoothness, and area\n",
    "\n",
    "From the built-in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer() #this is a python object that works like a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important dictionary keys: \n",
    "- classification label names (```target_names```), \n",
    "- the actual labels (```target```), \n",
    "- the attribute/feature names (```feature_names```), \n",
    "- and the attributes (```data```).\n",
    "\n",
    "In our case, possible useful attributes include the size, radius, and texture of the tumor  \n",
    "Creating python3 lists for the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "0\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "569\n",
      "30\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "label_names = data['target_names'] # source on python dictionaries https://www.w3schools.com/python/python_dictionaries.asp \n",
    "labels = data['target'] #access the items of a dictionary by referring to its key name, inside square brackets.\n",
    "feature_names = data['feature_names'] #kind of like C structs. feature_names is the name for the features below\n",
    "features = data['data'] #attributes aka features, the actual values themselves\n",
    "# Look at our data\n",
    "print(label_names)        # therefore, 0 represents malignant and 1 benign\n",
    "print(labels[0])          # then, from the prelabeled names, the first tumor in the list must be a malignant tumor\n",
    "print(feature_names)      # names for all the features \n",
    "print (len(features))     # there are 569 tumors\n",
    "print (len(features[0]))  # there are 30 different features in a tumor\n",
    "print(features[0])        # looking at mean radius of this tumor, we see is 1.79e+01 and the mean texture is 1.038e+01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to organize the data into sets. To evaluate how well the classifier/model performs, we need to do so on unseen data. Thus we have to split our data into training and testing data.\n",
    "```sklearn``` has a ```train_test_split()``` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function randomly splits the data using the ```test_size``` parameter.  \n",
    "In this example, we now have a test set (```test```) that represents 33% of the original dataset. The remaining data (```train```) then makes up the training data. We also have the respective labels for both the train/test variables, i.e. ```train_labels``` and ```test_labels```\n",
    "\n",
    "\n",
    "Bulding and training model:  \n",
    "the Naive Bayes (NB) algorithim usually performs well in binary classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize our classifier/model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier/model\n",
    "model = gnb.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, we can make predictions.  \n",
    "The ```predict()``` function returns an array of predictions for each data instance in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "preds = gnb.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evalute the model's accuracy by comparing to the pre-labelled values, using ```accuracy()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9414893617021277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the Naive Bayes classifier is 94% accurate here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
